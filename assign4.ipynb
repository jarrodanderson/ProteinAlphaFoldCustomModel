{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assign4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNOeMie3bi7GKq0iOSCIr/C"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"TADUnCi0hNxY","colab_type":"code","colab":{}},"source":["training_file = \"drive/My Drive/assign4data/training_30\"\n","validation_file = \"drive/My Drive/assign4data/validation\"\n","testing_file = \"drive/My Drive/assign4data/testing\"\n","ng_val = 1\n","\n","import glob\n","import os.path\n","import os\n","import platform\n","import numpy as np\n","import h5py\n","import torch\n","import torch.nn as nn\n","import torch.utils.model_zoo as model_zoo\n","from torch.nn.functional import softmax \n","import pickle as pkl\n","import random\n","import torch.optim as optim\n","import subprocess\n","import torch.utils.data\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"37CmG-snD6v9","colab_type":"code","colab":{}},"source":["#functions from util\n","AA_ID_DICT = {'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9,\n","              'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17,\n","              'V': 18, 'W': 19, 'Y': 20}\n","MAX_SEQUENCE_LENGTH = 100\n","def encode_primary_string(primary):\n","    return list([AA_ID_DICT[aa] for aa in primary])\n","\n","def calc_pairwise_distances(chain_a, chain_b, use_gpu):\n","    distance_matrix = torch.Tensor(chain_a.size()[0], chain_b.size()[0]).type(torch.float)\n","    # add small epsilon to avoid boundary issues\n","    epsilon = 10 ** (-4) * torch.ones(chain_a.size(0), chain_b.size(0))\n","    if use_gpu:\n","        distance_matrix = distance_matrix.cuda()\n","        epsilon = epsilon.cuda()\n","\n","    for idx, row in enumerate(chain_a.split(1)):\n","        distance_matrix[idx] = torch.sum((row.expand_as(chain_b) - chain_b) ** 2, 1).view(1, -1)\n","\n","    return torch.sqrt(distance_matrix + epsilon)\n","\n","def read_protein_from_file(file_pointer):\n","    \"\"\"The algorithm Defining Secondary Structure of Proteins (DSSP) uses information on e.g. the\n","    position of atoms and the hydrogen bonds of the molecule to determine the secondary structure\n","    (helices, sheets...).\n","    \"\"\"\n","    dict_ = {}\n","    _dssp_dict = {'L': 0, 'H': 1, 'B': 2, 'E': 3, 'G': 4, 'I': 5, 'T': 6, 'S': 7}\n","    _mask_dict = {'-': 0, '+': 1}\n","\n","    while True:\n","        next_line = file_pointer.readline()\n","        if next_line == '[ID]\\n':\n","            id_ = file_pointer.readline()[:-1]\n","            dict_.update({'id': id_})\n","        elif next_line == '[PRIMARY]\\n':\n","            primary = encode_primary_string(file_pointer.readline()[:-1])\n","            dict_.update({'primary': primary})\n","        elif next_line == '[EVOLUTIONARY]\\n':\n","            evolutionary = []\n","            for _residue in range(21):\n","                evolutionary.append([float(step) for step in file_pointer.readline().split()])\n","            dict_.update({'evolutionary': evolutionary})\n","        elif next_line == '[SECONDARY]\\n':\n","            secondary = list([_dssp_dict[dssp] for dssp in file_pointer.readline()[:-1]])\n","            dict_.update({'secondary': secondary})\n","        elif next_line == \"[TERTIARY]\\n\":\n","            tertiary = []\n","            # 3 dimension\n","            for _axis in range(3):\n","                values = file_pointer.readline().split()\n","                # for each atom N, C, C' get every C\n","                tertiary.append([float(values[i]) for i in range(1, len(values), 3)])\n","            dict_.update({\"tertiary\": tertiary})\n","        elif next_line == '[MASK]\\n':\n","            mask = list([_mask_dict[aa] for aa in file_pointer.readline()[:-1]])\n","            dict_.update({'mask': mask})\n","        elif next_line == '\\n':\n","            return dict_\n","        elif next_line == '':\n","            return None\n","\n","\n","def process_file(input_file, use_gpu):\n","\n","    input_file_pointer = open(input_file, \"r\")\n","    all_proteins = []\n","\n","    while True:\n","        # while there's more proteins to process\n","        next_protein = read_protein_from_file(input_file_pointer)\n","        if next_protein is None:\n","            break\n","\n","        sequence_length = len(next_protein['primary'])\n","\n","        if sequence_length > MAX_SEQUENCE_LENGTH:\n","            #print(\"Dropping protein as length too long:\", sequence_length)\n","            continue\n","\n","      \n","        \n","        primary_padded = np.zeros(MAX_SEQUENCE_LENGTH)\n","        tertiary_padded = np.zeros((3, MAX_SEQUENCE_LENGTH))\n","        mask_padded = np.zeros(MAX_SEQUENCE_LENGTH)\n","        evo_padded = np.zeros((21,MAX_SEQUENCE_LENGTH))\n","        # masking and padding here happens so that the stored dataset is of the same size.\n","        # when the data is loaded in this padding is removed again.\n","        primary_padded[:sequence_length] = next_protein['primary']\n","        t_transposed = np.ravel(np.array(next_protein['tertiary']).T)\n","        t_reshaped = np.reshape(t_transposed, (sequence_length, 3)).T\n","\n","        e_transposed = np.ravel(np.array(next_protein['evolutionary']).T)\n","        e_reshaped = np.reshape(e_transposed, (sequence_length,21)).T\n","\n","        tertiary_padded[:, :sequence_length] = t_reshaped\n","        evo_padded[:,:sequence_length] = e_reshaped\n","\n","\n","        mask_padded[:sequence_length] = next_protein['mask']\n","\n","        mask = torch.Tensor(mask_padded).type(dtype=torch.bool)\n","\n","        prim = torch.masked_select(torch.Tensor(primary_padded)\n","                                   .type(dtype=torch.long), mask)\n","        \n","        pos = torch.masked_select(torch.Tensor(tertiary_padded), mask)\\\n","                  .view(3, -1).transpose(0, 1).unsqueeze(1) / 100\n","\n","\n","\n","        \n","        tertiary = pos.squeeze(1)\n","\n","        evol = torch.masked_select(torch.Tensor(evo_padded), mask)\\\n","                  .view(21, -1).transpose(0, 1).unsqueeze(1) / 100\n","\n","        \n","        evolutionary = evol.squeeze(1)\n","\n","        primary_padded = np.zeros(MAX_SEQUENCE_LENGTH)\n","        tertiary_padded = np.zeros((MAX_SEQUENCE_LENGTH, 3))\n","        evo_padded = np.zeros((MAX_SEQUENCE_LENGTH,21))\n","        length_after_mask_removed = len(prim)\n","\n","        primary_padded[:length_after_mask_removed] = prim.data.cpu().numpy()\n","        tertiary_padded[:length_after_mask_removed, :] = tertiary.data.cpu().numpy()\n","        evo_padded[:length_after_mask_removed, :] = evolutionary.data.cpu().numpy()\n","        mask_padded = np.zeros(MAX_SEQUENCE_LENGTH)\n","        mask_padded[:length_after_mask_removed] = np.ones(length_after_mask_removed)\n","        dict_ = {}\n","        dict_['primary'] = primary_padded\n","        dict_['tertiary'] = tertiary_padded\n","        dict_['mask_padded'] = mask_padded\n","        dict_['evolutionary'] = evo_padded\n","        dict_['seq_len'] = sequence_length\n","        all_proteins.append(dict_)\n","\n","    return all_proteins\n","\n","def sequence_onehot(seq):\n","    \"\"\"Maps the given sequence into a one-hot encoded matrix.\"\"\"\n","    one_hot = np.zeros((len(seq), 20), dtype=np.int32)\n","\n","    for aa_index, aa_id in enumerate(seq):\n","        one_hot[int(aa_index), int(aa_id) - 1] = 1\n","\n","    return torch.Tensor(one_hot).float()\n","\n","def seq2block(prim_msa_i, prim_msa_j):\n","    # takes each prot fi and returns n*n*f block were fij = |fi cat fj|\n","    # todo: add options to have dim=2 be different options such as |fi cat fj|fi * fj|\n","    # prim_msa shape should be (prot_len x 41d)\n","    seq_len = prim_msa_i.shape[0]\n","    fij = torch.zeros((seq_len, seq_len, prim_msa_i.shape[1] * 2))\n","    for idx, i in enumerate(prim_msa_i):\n","        for jdx, j in enumerate(prim_msa_j):\n","            fij[idx][jdx] = torch.cat((i, j))\n","    return fij\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zc8CvfvX_EvN","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.utils.model_zoo as model_zoo\n","from torch.nn.functional import softmax \n","import pickle as pkl\n","import numpy as np\n","import random\n","import torch.optim as optim\n","import subprocess\n","import torch.utils.data\n","#helper functions\n","#GLOBAL VARIABLE\n","INPUT_DIM = 82\n","OUTPUT_BINS = 65 #number of bins in output\n","RESNET_DIM = 128 #number of layers inside of resnet\n","\n","\n","class BasicBlock(nn.Module):\n","\n","    def __init__(self, dilation = 1):\n","        super(BasicBlock, self).__init__()\n","        norm_layer = nn.BatchNorm2d\n","        self.project_down = conv1x1(128, 64, stride=1)\n","        self.project_up   = conv1x1(64, 128, stride=1)\n","        self.bn64_1 = norm_layer(64)\n","        self.bn64_2 = norm_layer(64)\n","        self.bn128 = norm_layer(128)\n","\n","        #dilations deal now with 64 incoming and 64 outcoming layers\n","        self.dilation = conv3x3(64, 64, stride=1, dilation = dilation) #when the block is initialized, the only thing that changes is the dilation filter used!\n","        self.elu = nn.ELU(inplace=True)\n","\n","    def forward(self, x):\n","        \n","        identity = x\n","    \n","        #the deepmind basic block goes:\n","        \n","        #batchnorm\n","        out = self.bn128(x)\n","        \n","        #elu\n","        out = self.elu(out)\n","    \n","        #project down to 64\n","        out = self.project_down(out)\n","        \n","        #batchnorm\n","        out = self.bn64_1(out)\n","\n","        #elu\n","        out = self.elu(out)   \n","        \n","        #cycle through 4 dilations\n","        out = self.dilation(out)  \n","        \n","        #batchnorm\n","        out = self.bn64_2(out)\n","\n","        #elu\n","        out = self.elu(out)\n","        \n","        #project up to 128\n","        out = self.project_up(out)\n","        \n","        #identitiy addition \n","        out = out + identity\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self,n_groups):\n","        super(ResNet, self).__init__()\n","        self.inplanes = RESNET_DIM\n","        \n","        self.conv1 = conv1x1(INPUT_DIM, RESNET_DIM, stride=1)\n","        self.conv2 = conv1x1(RESNET_DIM, OUTPUT_BINS )\n","\n","        self.resnet_blocks = self._make_layer(n_groups)\n","\n","\n","    def _make_layer(self, n_groups):\n","        layers = []\n","        #here I need to pass in the correct dilations 1,2,4,8\n","        dilations = [1,2,4,8]\n","        for i,_ in enumerate(range(0, n_groups)):\n","            layers.append(BasicBlock( dilation = dilations[i]))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        #fix input dimensions\n","        x = self.conv1(x)\n","  \n","        #propagate through RESNET blocks\n","        resnet_out = self.resnet_blocks(x)\n","        #renet_out has shape 1,128,64,64\n","        \n","        #fix output dimensions\n","        x = self.conv2(resnet_out)\n","        #FIX THIS TO WORK WITH BATCHES!\n","        m = nn.Softmax2d()\n","        return m(x)\n","\n","\n","def is_training():\n","    pass  # change BATCH_SIZE\n","\n","def conv3x3(in_planes, out_planes, stride=1, dilation = 1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    padding = 1 + (dilation -1 ) #derived to ensure consistent size\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=padding, bias=True, dilation = dilation)\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=True)\n","\n","def conv64x1(in_planes, out_planes, stride=1, groups=1):\n","    \"\"\"64x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=(64,1), stride=stride, groups=groups, bias=True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cIpiaN-7RNpY","colab_type":"code","colab":{}},"source":["from torch.utils.data import IterableDataset\n","class Sequences(IterableDataset):\n","  def __init__(self, final_input):\n","    self.data = final_input # [(prim_msa,tertiary),()....]\n","    self.bins= np.arange(float(2),float(22), float(20/64))\n","  def get_tile(self, p, i , j):\n","    prim_msa_i = self.data[p][0][i:i+64]\n","    prim_msa_j = self.data[p][0][j:j+64]\n","    return seq2block(prim_msa_i,prim_msa_j)\n","  def get_dmat(self, p, i, j):\n","    prim_msa_i = self.data[p][1][i:i+64]\n","    prim_msa_j = self.data[p][1][j:j+64]\n","    return calc_pairwise_distances(prim_msa_i,prim_msa_j,False)\n","  def bin_dmat(self, dmat):\n","    return np.digitize(dmat,self.bins)\n","  def __len__(self):\n","    return len(self.data)\n","  def __iter__(self):\n","    self.p =0\n","    self.i=0\n","    self.j=0\n","    return self\n","  def __next__(self):\n","    if(self.p<len(self.data)):\n","      a = self.get_tile(self.p,self.i,self.j)\n","    else:\n","      raise StopIteration\n","    a = a.permute(2,0,1)\n","    b_unbinned = self.get_dmat(self.p,self.i,self.j)\n","    b = self.bin_dmat(b_unbinned)\n","    ret_i = self.i\n","    ret_j = self.j\n","    ret_n = self.data[self.p][2]\n","    ret_p = self.p\n","    self.j = self.j+32\n","    if( self.j > len(self.data[self.p][0])-64):\n","      self.j = 0\n","      self.i += 32\n","    if(self.i > len(self.data[self.p][0])-64 ):\n","      self.i =0\n","      self.j =0\n","      self.p +=1\n","    if(self.p>=len(self.data)):\n","        raise StopIteration\n","    return (a,b,(ret_i,ret_j, ret_n, ret_p))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AmY-u4JOgA7k","colab_type":"code","outputId":"23687262-27a9-48fd-b281-23c3c651ffc8","executionInfo":{"status":"ok","timestamp":1588212387629,"user_tz":240,"elapsed":61589,"user":{"displayName":"Rahul Puppala","photoUrl":"https://lh6.googleusercontent.com/-a3E4o0T7KT8/AAAAAAAAAAI/AAAAAAAAAq4/SoPeLsACGtc/s64/photo.jpg","userId":"12827901970476877756"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# SKIP THIS IF RUNNING LOCAL\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"glsYNtLRE9ZH","colab_type":"code","colab":{}},"source":["x = process_file(training_file,use_gpu=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_o_s6-93FQv","colab_type":"code","colab":{}},"source":["valid = process_file(validation_file,use_gpu=False)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dO4OhLHSXZu","colab_type":"code","colab":{}},"source":["test = process_file(testing_file,use_gpu=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkFmcsPSIvWm","colab_type":"code","colab":{}},"source":["# one hotting the primary and concatenating with MSA\n","for protein in x:\n","  one_hot = sequence_onehot(protein['primary'])\n","  evo_tensor = torch.Tensor(protein['evolutionary']).float()\n","  protein['prim_msa_cat'] = torch.cat((one_hot,evo_tensor),1)\n","\n","# one hotting the primary and concatenating with MSA -- validation data\n","for protein in valid:\n","  one_hot = sequence_onehot(protein['primary'])\n","  evo_tensor = torch.Tensor(protein['evolutionary']).float()\n","  protein['prim_msa_cat'] = torch.cat((one_hot,evo_tensor),1)\n","\n","# one hotting the primary and concatenating with MSA -- validation data\n","for protein in test:\n","  one_hot = sequence_onehot(protein['primary'])\n","  evo_tensor = torch.Tensor(protein['evolutionary']).float()\n","  protein['prim_msa_cat'] = torch.cat((one_hot,evo_tensor),1)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CXxX8vVlMful","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"pcAA1kB7tkt5","colab_type":"code","colab":{}},"source":["final_input = []\n","for protein in x:\n","  final_input.append((protein['prim_msa_cat'],torch.Tensor(protein['tertiary']).float(),protein['seq_len']))\n","\n","valid_input = []\n","for protein in valid:\n","  valid_input.append((protein['prim_msa_cat'],torch.Tensor(protein['tertiary']).float(),protein['seq_len']))\n","\n","test_input = []\n","for protein in test:\n","  test_input.append((protein['prim_msa_cat'],torch.Tensor(protein['tertiary']).float(),protein['seq_len']))\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mCSe1DxuGAj1","colab_type":"code","outputId":"60e03545-b9da-4a76-d722-aeed23a3366a","executionInfo":{"status":"ok","timestamp":1588212444280,"user_tz":240,"elapsed":259,"user":{"displayName":"Rahul Puppala","photoUrl":"https://lh6.googleusercontent.com/-a3E4o0T7KT8/AAAAAAAAAAI/AAAAAAAAAq4/SoPeLsACGtc/s64/photo.jpg","userId":"12827901970476877756"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(len(final_input))\n","print(len(valid_input))\n","print(len(test_input))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2876\n","61\n","12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KRCxt1e3Lyka","colab_type":"code","colab":{}},"source":["train_data = Sequences(final_input)\n","dataloader = torch.utils.data.DataLoader(train_data, batch_size =4, num_workers = 1)\n","\n","valid_data = Sequences(valid_input)\n","valid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size =4, num_workers = 1)\n","\n","test_data = Sequences(test_input)\n","test_dataloader = torch.utils.data.DataLoader(test_data, batch_size =1, num_workers = 1)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AM4p3YCYwhfv","colab_type":"code","colab":{}},"source":["def train_model(model, n_epochs):\n","    train_losses = []\n","    # to track the validation loss as the model trains\n","    valid_losses = []\n","    # to track the average training loss per epoch as the model trains\n","    avg_train_losses = []\n","    # to track the average validation loss per epoch as the model trains\n","    avg_valid_losses = []\n","    \n","    \n","    for e in range(1,n_epochs+1):\n","        model.train()\n","        ###################\n","        # train the model #\n","        ###################\n","        for(batch,(data,target,(_,_,_,_))) in enumerate(dataloader):\n","            if(batch%1000==0):\n","              print(batch)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","            train_losses.append(loss.item())\n","        ######################    \n","        # validate the model #\n","        ######################\n","        model.eval() # prep model for evaluation\n","  \n","        for (batch,(data, target,(_,_,_,_))) in enumerate(valid_dataloader):\n","            if(batch%50==0):\n","              print(batch)\n","            # forward pass: compute predicted outputs by passing inputs to the model\n","            output = model(data)\n","            # calculate the loss\n","            loss = criterion(output, target)\n","            # record validation loss\n","            valid_losses.append(loss.item())\n","        train_loss = np.average(train_losses)\n","        valid_loss = np.average(valid_losses)\n","        avg_train_losses.append(train_loss)\n","        avg_valid_losses.append(valid_loss)\n","        epoch_len = len(str(n_epochs))\n","        \n","        print_msg = (f'[{e:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n","                      f'train_loss: {train_loss:.5f} ' +\n","                      f'valid_loss: {valid_loss:.5f}')\n","\n","        print(print_msg)\n","          \n","        # clear lists to track next epoch\n","        train_losses = []\n","        valid_losses = []\n","    return  model, avg_train_losses, avg_valid_losses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3z-bcYNvBMF","colab_type":"code","colab":{}},"source":["model = ResNet(ng_val)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HOIDp8zq4W-W","colab_type":"code","outputId":"b311cb8f-37fc-4d93-ec23-570bb41a4039","executionInfo":{"status":"error","timestamp":1588212463810,"user_tz":240,"elapsed":7844,"user":{"displayName":"Rahul Puppala","photoUrl":"https://lh6.googleusercontent.com/-a3E4o0T7KT8/AAAAAAAAAAI/AAAAAAAAAq4/SoPeLsACGtc/s64/photo.jpg","userId":"12827901970476877756"}},"colab":{"base_uri":"https://localhost:8080/","height":358}},"source":["\n","model, train_loss, valid_loss = train_model(model, 1)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-87dd166fd8ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-8a9e621435b8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, n_epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"tsJh7JrTy3aB","colab_type":"code","colab":{}},"source":["import math\n","def Average(lst): \n","    return sum(lst) / len(lst) \n","def test_model(model):\n","  test_dataloader = torch.utils.data.DataLoader(test_data, batch_size =1, num_workers = 1)\n","  all_preds = []\n","  p_len = {}\n","  for (batch,(data,target,(i_off,j_off,seq_len,p_num))) in enumerate(test_dataloader):\n","    p_len[p_num.item()] = seq_len.item()\n","  for i in range(0,len(test_data)):\n","    temp = [[1 for j in range(MAX_SEQUENCE_LENGTH)] for i in range(MAX_SEQUENCE_LENGTH)]\n","    for j in range(0,MAX_SEQUENCE_LENGTH):\n","      for k in range(0,MAX_SEQUENCE_LENGTH):\n","        temp[j][k] = (-1,0,0) # (true label , summed probability, contact or not)\n","    all_preds.append(temp)\n","  for (batch,(data,target,(i_off,j_off,seq_len,p_num))) in enumerate(test_dataloader):\n","    output = model(data)\n","    output = output.squeeze(0)\n","    target = target.squeeze(0)\n","    summed = torch.sum(output[0:20],dim=0)  \n","    for i in range(0,64):\n","      for j in range(0,64):\n","        if(all_preds[p_num][i+i_off][j+j_off][0] == -1):\n","          if(target[i][j]<20):\n","            x=1\n","          else:\n","            x=0\n","          y = summed[i][j].item()\n","          if(all_preds[p_num][i+i_off][j+j_off][1]>=.5):\n","            z = 1\n","          else:\n","            z = 0\n","          all_preds[p_num][i+i_off][j+j_off] = (x,y,z)\n","\n","  accuracy = []\n","  accuracy2 = []\n","  accuracy5 = []\n","  for i,preds in enumerate(all_preds):\n","    num_correct = 0\n","    total = 0\n","    for j in range(0,min(95,p_len[i])):\n","      for k in range(0,min(95,p_len[i])):\n","        total+=1\n","        if(preds[j][k][0]==preds[j][k][2]):\n","          num_correct+=1\n","    accuracy.append(num_correct/total)\n","    flat = [j for sub in preds[0:p_len[i]][0:p_len[i]] for j in sub] \n","    flat.sort(key=lambda x:x[1])\n","    flat_2 = flat[0:math.floor(len(flat)/2)]\n","    flat_5 = flat[0:math.floor(len(flat)/5)]\n","    num_correct=0\n","    total=0\n","    for j in range(0,len(flat_2)):\n","      total+=1\n","      if(flat_2[j][0]==flat_2[j][2]):\n","        num_correct+=1\n","    accuracy2.append(num_correct/total)\n","    num_correct=0\n","    total=0\n","    for j in range(0,len(flat_5)):\n","      total+=1\n","      if(flat_5[j][0]==flat_5[j][2]):\n","        num_correct+=1\n","    accuracy5.append(num_correct/total)\n","  print(\"N-Accuracy: \",Average(accuracy))\n","  print(\"N/2-Accuracy: \",Average(accuracy2))\n","  print(\"N/5-Accuracy: \",Average(accuracy5))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ci9ajP1g0uY1","colab_type":"code","outputId":"624c8d8c-b9f6-4b58-9c7b-1e42f14adb24","executionInfo":{"status":"ok","timestamp":1588212482534,"user_tz":240,"elapsed":12671,"user":{"displayName":"Rahul Puppala","photoUrl":"https://lh6.googleusercontent.com/-a3E4o0T7KT8/AAAAAAAAAAI/AAAAAAAAAq4/SoPeLsACGtc/s64/photo.jpg","userId":"12827901970476877756"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["test_model(model)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{0: 68, 1: 97, 2: 97, 3: 85, 4: 90, 5: 97, 6: 87, 7: 85, 8: 95, 9: 93, 10: 75, 11: 76}\n","0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","N-Accuracy:  0.8539467263599948\n","N/2-Accuracy:  0.7928717507537894\n","N/5-Accuracy:  0.671322799064229\n"],"name":"stdout"}]}]}